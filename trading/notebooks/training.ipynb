{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from rich import print as rprint\n",
    "\n",
    "from trading.src.user_cache.user_cache import UserCache as user_cache\n",
    "user = user_cache.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74718d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- PARAMETERS ----\n",
    "ALPACA_API_KEY = user.alpaca_api_key.get_secret_value()\n",
    "ALPACA_SECRET_KEY = user.alpaca_api_secret.get_secret_value()\n",
    "TICKERS = [\"AAPL\"]  # or use [\"AAPL\", \"MSFT\", ...] for all tickers\n",
    "START_DATE = \"2000-01-01\"\n",
    "END_DATE = \"2023-01-01\"\n",
    "CACHE_FILE = \"alpaca_cache.parquet\"\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "OVERFITTING_PARAM = 0.05  # e.g., weight decay\n",
    "SAVE_PARAMS = False\n",
    "PARAMS_FILE = \"run_params.json\"\n",
    "LEARNING_RATE = 2e-5\n",
    "HOLD_THRESHOLD=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a9789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- DATA COLLECTION & CACHING ----\n",
    "def fetch_and_cache_data(tickers, start, end, cache_file):\n",
    "    if os.path.exists(cache_file):\n",
    "        rprint(\"Loading data from cache...\")\n",
    "        df = pd.read_parquet(cache_file)\n",
    "    else:\n",
    "        rprint(\"Fetching data from Alpaca...\")\n",
    "        client = StockHistoricalDataClient(ALPACA_API_KEY, ALPACA_SECRET_KEY)\n",
    "        all_data = []\n",
    "        for ticker in tickers:\n",
    "            request_params = StockBarsRequest(\n",
    "                symbol_or_symbols=ticker,\n",
    "                timeframe=TimeFrame.Day,\n",
    "                start=pd.to_datetime(start),\n",
    "                end=pd.to_datetime(end)\n",
    "            )\n",
    "            bars = client.get_stock_bars(request_params).df\n",
    "            bars['ticker'] = ticker\n",
    "            all_data.append(bars)\n",
    "        df = pd.concat(all_data)\n",
    "        df.to_parquet(cache_file)\n",
    "    return df\n",
    "\n",
    "df = fetch_and_cache_data(TICKERS, START_DATE, END_DATE, CACHE_FILE)\n",
    "rprint(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca88cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- FEATURE ENGINEERING ----\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df['return'] = df['close'].pct_change()\n",
    "    df['ma5'] = df['close'].rolling(window=5).mean()\n",
    "    df['ma10'] = df['close'].rolling(window=10).mean()\n",
    "    df['volatility'] = df['close'].rolling(window=5).std()\n",
    "    df['target'] = (df['close'].shift(-1) > df['close']).astype(int)  # 1 if next day up, else 0\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# 0 = SELL, 1 = HOLD, 2 = BUY\n",
    "def add_trading_signals(df, hold_threshold=0.002):\n",
    "    df = df.copy()\n",
    "    df['future_return'] = df['close'].shift(-1) / df['close'] - 1\n",
    "    # BUY if next day's return > hold_threshold, SELL if < -hold_threshold, else HOLD\n",
    "    df['signal'] = np.where(df['future_return'] > hold_threshold, 2, \n",
    "                    np.where(df['future_return'] < -hold_threshold, 0, 1))\n",
    "    df = df.dropna()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38517151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = add_trading_signals(df, hold_threshold=HOLD_THRESHOLD)\n",
    "df = add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- DATA VISUALIZATION ----\n",
    "df_plot = df.reset_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_plot['timestamp'], df_plot['close'], label='Close Price')\n",
    "plt.plot(df_plot['timestamp'], df_plot['ma5'], label='MA5')\n",
    "plt.plot(df_plot['timestamp'], df_plot['ma10'], label='MA10')\n",
    "plt.title(f\"{TICKERS[0]} Price and Moving Averages\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- DATA PREPARATION ----\n",
    "features = ['open', 'high', 'low', 'close', 'volume', 'ma5', 'ma10', 'volatility']\n",
    "X = df[features].values\n",
    "y = df['signal'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b39ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f924baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP3(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfitLoss(torch.nn.Module):\n",
    "    def __init__(self, close_prices):\n",
    "        super().__init__()\n",
    "        self.close_prices = torch.tensor(close_prices, dtype=torch.float32).to(device)\n",
    "\n",
    "    def forward(self, outputs, targets, indices):\n",
    "        # outputs: [batch, 3], targets: [batch], indices: [batch]\n",
    "        probs = torch.softmax(outputs, dim=1)  # [batch, 3]\n",
    "\n",
    "        batch_close = self.close_prices[indices]\n",
    "        batch_next_close = self.close_prices[indices + 1]\n",
    "        change = (batch_next_close - batch_close) / batch_close  # percent change\n",
    "\n",
    "        # profit = [SELL, HOLD, BUY]\n",
    "        # SELL = price drops → profit\n",
    "        # BUY = price rises → profit\n",
    "        # HOLD = 0\n",
    "        profit_vector = torch.stack([\n",
    "            -change,                     # SELL\n",
    "            torch.zeros_like(change),   # HOLD\n",
    "            change                      # BUY\n",
    "        ], dim=1)  # [batch, 3]\n",
    "\n",
    "        expected_profit = torch.sum(probs * profit_vector, dim=1)  # [batch]\n",
    "        loss = -expected_profit.mean()  # negative to maximize expected profit\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = SimpleMLP(X_train.shape[1]).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=OVERFITTING_PARAM)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = SimpleMLP3(X_train.shape[1]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=OVERFITTING_PARAM)\n",
    "profit_loss_fn = ProfitLoss(df['close'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaca77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- TRAINING LOOP ----\n",
    "def train_model(model, X_train, y_train, epochs, batch_size):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        permutation = np.random.permutation(len(X_train))\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x = torch.tensor(X_train[indices], dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(y_train[indices], dtype=torch.long).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / (len(X_train) // batch_size)\n",
    "        rprint(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# profit-based loss\n",
    "def train_model_profit(model, X_train, y_train, epochs, batch_size):\n",
    "    model.train()\n",
    "    n = len(X_train)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        permutation = np.random.permutation(n-1)  # n-1 to avoid index error with next day's price\n",
    "        for i in range(0, n-batch_size, batch_size):  # ensure we have enough samples for next day's price\n",
    "            batch_indices = permutation[i:i+batch_size]\n",
    "            batch_x = torch.tensor(X_train[batch_indices], dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(y_train[batch_indices], dtype=torch.long).to(device)\n",
    "            batch_indices_tensor = torch.as_tensor(batch_indices, dtype=torch.long, device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            # Use the custom profit-based loss function\n",
    "            loss = profit_loss_fn(outputs, batch_y, batch_indices_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "        avg_loss = total_loss / batch_count\n",
    "        rprint(f\"Epoch {epoch+1}/{epochs}, Profit-based Loss: {avg_loss:.6f}\")\n",
    "\n",
    "train_model_profit(model, X_train, y_train, EPOCHS, BATCH_SIZE)\n",
    "\n",
    "# Uncomment to use standard cross-entropy training instead\n",
    "# train_model(model, X_train, y_train, EPOCHS, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- TESTING ----\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    outputs = model(X_test_tensor)\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    rprint(\"Test Accuracy:\", acc)\n",
    "    rprint(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- PARAMETER SAVING ----\n",
    "if SAVE_PARAMS:\n",
    "    params = {\n",
    "        \"tickers\": TICKERS,\n",
    "        \"start_date\": START_DATE,\n",
    "        \"end_date\": END_DATE,\n",
    "        \"features\": features,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"overfitting_param\": OVERFITTING_PARAM,\n",
    "        \"test_accuracy\": acc\n",
    "    }\n",
    "    with open(PARAMS_FILE, \"w\") as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "    rprint(f\"Parameters saved to {PARAMS_FILE}\")\n",
    "\n",
    "# ---- EXTENSIONS ----\n",
    "# - To use all tickers, set TICKERS to a list of all tickers.\n",
    "# - Add more features/signals in add_features().\n",
    "# - Tune EPOCHS, OVERFITTING_PARAM, etc.\n",
    "# - Add profit simulation by trading on model predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramblingrealms-trading-RC3nh33Z-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
